{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Voting Ennsemble  - Penguin Species Dataset"
      ],
      "metadata": {
        "id": "buV9E0bf-37g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING THE DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "HNvHInaq_BMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eum2WGOnBeeL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the ML / Scikit learn EVERYTHING"
      ],
      "metadata": {
        "id": "egI1aKHM_G4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier                 #Decision tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier   # bagging and Boosting\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score   # different metrices to check how our model performed"
      ],
      "metadata": {
        "id": "dy4Bw0vn4yUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Deep learning Everything"
      ],
      "metadata": {
        "id": "7EOOII0y82hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "O1qjFngb87Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing mathematical models"
      ],
      "metadata": {
        "id": "5oPnYaeAM0_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import the mathematical testing framewroks\n",
        "\n",
        "# Importing mathematical models\n",
        "import math\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "G_2PyN5pNV1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifiers for Same algorithm"
      ],
      "metadata": {
        "id": "JgfgK5gAoklP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X ,  y = make_classification(n_samples=1000, n_informative=15,n_redundant=5 , random_state=2)\n",
        "\n",
        "svm1 = SVC(probability=True , kernel='poly', degree=1)\n",
        "svm2 = SVC(probability=True , kernel='poly', degree=2)\n",
        "svm3 = SVC(probability=True , kernel='poly', degree=3)\n",
        "svm4 = SVC(probability=True , kernel='poly', degree=4)\n",
        "svm5 = SVC(probability=True , kernel='poly', degree=5)\n",
        "\n",
        "estimators = [( 'svm1' , svm1),( 'svm2' , svm2),( 'svm3' , svm3),( 'svm4' , svm4),( 'svm5' , svm5)]\n",
        "\n",
        "for estimator in estimators:\n",
        "    x = cross_val_score(estimator[1], X, y, cv=10, scoring='accuracy')\n",
        "    print(estimator[0], np.round(np.mean(x), 2))"
      ],
      "metadata": {
        "id": "N9rK3y0RpOzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hard Voting on Same Algorithm"
      ],
      "metadata": {
        "id": "foYtxNR9xGpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vc1 = VotingClassifier(estimators=estimators, voting='hard')\n",
        "x = cross_val_score(vc1, X, y, cv=10, scoring='accuracy')\n",
        "print(np.round(np.mean(x), 2))"
      ],
      "metadata": {
        "id": "nWTOYnKaxTYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Soft Voting on Same Algorithm"
      ],
      "metadata": {
        "id": "WaW0qzcgxU2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vc2 = VotingClassifier(estimators=estimators, voting='soft')\n",
        "x = cross_val_score(vc2, X, y, cv=10, scoring='accuracy')\n",
        "print(np.round(np.mean(x), 2))"
      ],
      "metadata": {
        "id": "Abo2sqwAxaN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted Voting on Same Algorithm"
      ],
      "metadata": {
        "id": "Q2Qke1y3xjyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for  i in range(1,3):\n",
        "  for j in range ( 1,3):\n",
        "    for k in range (4,5):\n",
        "      for l in range (1,2):\n",
        "        for m in range (2,4):\n",
        "         vc = VotingClassifier(estimators=estimators,weights=[i,j,k,l,m])\n",
        "         x = cross_val_score(vc,X,y,cv=10,scoring='accuracy')\n",
        "         print (f'for i = {i} , j = {j} , k = {k} , l = {l} ,m={m}, the accuracy is {np.round(np.mean(x),2)}')"
      ],
      "metadata": {
        "id": "C2CAbJTtxpdk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
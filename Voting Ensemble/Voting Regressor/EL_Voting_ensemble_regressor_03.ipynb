{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Voting Ennsemble Regressor - Admission Dataset"
      ],
      "metadata": {
        "id": "buV9E0bf-37g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING THE DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "HNvHInaq_BMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eum2WGOnBeeL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the ML / Scikit learn EVERYTHING"
      ],
      "metadata": {
        "id": "egI1aKHM_G4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier                 #Decision tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier   # bagging and Boosting\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score   # different metrices to check how our model performed"
      ],
      "metadata": {
        "id": "dy4Bw0vn4yUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Deep learning Everything"
      ],
      "metadata": {
        "id": "7EOOII0y82hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "O1qjFngb87Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing mathematical models"
      ],
      "metadata": {
        "id": "5oPnYaeAM0_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import the mathematical testing framewroks\n",
        "\n",
        "# Importing mathematical models\n",
        "import math\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "G_2PyN5pNV1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Information about the Dataset"
      ],
      "metadata": {
        "id": "XTPRT3iy9EuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files    # we are importing the file from the device\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "GiKUuK2LUcY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical encoding has already being performed"
      ],
      "metadata": {
        "id": "u9tMczjh9x1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Admission_Dataset.csv')   #fitting the data in the df dataframe\n",
        "df.head(100)"
      ],
      "metadata": {
        "id": "PAXRZRNaJVKO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "fkHEM3gG747n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Serial No.', axis=1)"
      ],
      "metadata": {
        "id": "7ymqaQZgFUf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "tI7KmcrM79Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "i0p4tkGa8LcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " There is no null data present in our Dataset"
      ],
      "metadata": {
        "id": "wUxiZbKg8QuQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "YP84BY9b8Zdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()          # Checking the Duplicate Columns"
      ],
      "metadata": {
        "id": "iUBfdUMF8dqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standard Scaling the numeric values"
      ],
      "metadata": {
        "id": "p7-0H-rSAg7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df\n"
      ],
      "metadata": {
        "id": "dsWukBRO_6AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns =  ['GRE Score', 'TOEFL Score','University Rating','SOP','LOR ','CGPA','Chance of Admit ']\n",
        "\n",
        "\n",
        "def remove_outliers(df , columns ):       # Outlier detection of the Numeric columns\n",
        "  for col in columns:\n",
        "\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "\n",
        "  return df\n",
        "\n",
        "df = remove_outliers(df , numerical_columns)"
      ],
      "metadata": {
        "id": "XePWWals8sqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "DFg8iLD9YB0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])"
      ],
      "metadata": {
        "id": "F-OkP875As0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using Inter-quartile Range to find the ouliers in the Numerical Continuous Values of the Numerical columns that we have"
      ],
      "metadata": {
        "id": "hLGjtdxj-gIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize (df , columns):      # Normalization  of the Numeric Columns\n",
        "\n",
        "  pt = PowerTransformer(method='yeo-johnson')     # Power transformation will help us a Gaussian / Normal Distribution\n",
        "\n",
        "  for col in columns:\n",
        "\n",
        "    skewness = skew(df[col])       # for skewness more than 0.5\n",
        "    if abs(skewness) > 0.5:\n",
        "      df[col] = pt.fit_transform(df[[col]].values.reshape(-1,1))\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "  df = normalize(df , numerical_columns)"
      ],
      "metadata": {
        "id": "8c5RXioe-3tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "hr_0O7UqGdpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis ( EDA )"
      ],
      "metadata": {
        "id": "4PmJ4wEfBBUV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Distribution of NUMERIC FEATURES and Analysis"
      ],
      "metadata": {
        "id": "noe8bZQyhtlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution plots for numerical features\n",
        "plt.figure(figsize=(18, 18))\n",
        "\n",
        "\n",
        "for i, col in enumerate(numerical_columns):\n",
        "    plt.subplot(4, 3, i + 1)\n",
        "    sns.histplot(df[col], bins=30, kde=True , palette='Set3')\n",
        "    plt.title(f'{col} Distribution')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vIOVnALRFzbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us the 6 graphs for 6 features that we had\n",
        "\n",
        "All the graphs are basically distribution graphs removing the Outliers"
      ],
      "metadata": {
        "id": "NVnj2FGsGLLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multivariate Analysis of the Numeric Features"
      ],
      "metadata": {
        "id": "v786dOgMDShs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot to show relationships between features\n",
        "plt.figure(figsize=(15, 15))\n",
        "sns.pairplot(df[numerical_columns ], palette='Set3')\n",
        "plt.suptitle('Pairplot of Numerical Features', y=1.02)\n",
        "plt.show()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mLf3IlGODxTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(20, 15))\n",
        "numeric_data = df[numerical_columns]\n",
        "sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k7uYBjmbDTGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning"
      ],
      "metadata": {
        "id": "MhDL52jIPpKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df\n"
      ],
      "metadata": {
        "id": "14KN7jtZGqU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df.columns)\n",
        "\n",
        "#X = df.drop('Chance of Admit ',axis=1)  # Corrected column name\n",
        "y = df['Chance of Admit ']  # Corrected column name\n",
        "\n",
        "X  = df[['GRE Score', 'TOEFL Score','CGPA' ,'SOP','University Rating']]  # TAking the most correlated columns for our Target that is chance of admission"
      ],
      "metadata": {
        "id": "eutfX6iBJBlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GuME9WSSP4fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor"
      ],
      "metadata": {
        "id": "JV02z_IZLZmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Machine Learning Models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Decision Tree': DecisionTreeRegressor(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'SVm': SVR(),\n",
        "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(),\n",
        "    'Neural Network': MLPRegressor(max_iter=50)\n",
        "}"
      ],
      "metadata": {
        "id": "TUf1joZXLkMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score , root_mean_squared_error"
      ],
      "metadata": {
        "id": "EnkIy2mSPoYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    #y_proba = model.predict_proba(X_test)#[:, #0]\n",
        "\n",
        "    results.append({\n",
        "        'Model': model_name,\n",
        "        'MAE':mean_absolute_error(y_test, y_pred),\n",
        "\n",
        "        'MSE': mean_squared_error(y_test, y_pred),\n",
        "        'R2_square': r2_score(y_test, y_pred),\n",
        "        'RMSE': root_mean_squared_error(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.sort_values(by='R2_square', ascending=False, inplace=True)\n",
        "\n",
        "results_df"
      ],
      "metadata": {
        "id": "Th9G5oIvP96F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voting Ensemble"
      ],
      "metadata": {
        "id": "DOR9p8B1aNZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = LinearRegression()\n",
        "r2 = RandomForestRegressor()\n",
        "r3 = GradientBoostingRegressor()\n",
        "\n",
        "\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "estimators = [('lr',r1),('rf',r2),('gb',r3)]  #estimators are get the top 3 models for our\n",
        "\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "Ce-_uUhfaQis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for estimator in estimators:\n",
        "  scores = cross_val_score(estimator[1],X,y,cv=10 ,scoring = 'r2' )   # we are calculating the cross validation score\n",
        "  print(estimator[0],np.round(np.mean(scores),2))   # we are finding the mean of all the cross validation score AND STORE IT IN THE ARRAY NAMED SCORE"
      ],
      "metadata": {
        "id": "S1Wb7JZ1a1wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hard Voting"
      ],
      "metadata": {
        "id": "a38KhIPfeu16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vr = VotingRegressor(estimators=estimators)  # default voting is hard\n",
        "\n",
        "\n",
        "x = cross_val_score(vr,X,y,cv=10,scoring='r2')\n",
        "print(np.round(np.mean(x),2))"
      ],
      "metadata": {
        "id": "qyafcGu7euQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Weighted Voting"
      ],
      "metadata": {
        "id": "8w5w6gHbiRFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for  i in range(3,6):\n",
        "  for j in range ( 1,3):\n",
        "    for k in range (1,3):\n",
        "        vr = VotingRegressor(estimators=estimators,weights=[i,j,k])\n",
        "        x = cross_val_score(vr,X,y,cv=10,scoring='r2')\n",
        "        print (f'for i = {i} , j = {j} , k = {k}  , the r2 score is {np.round(np.mean(x),2)}')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4Z6pxoW2iLEj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
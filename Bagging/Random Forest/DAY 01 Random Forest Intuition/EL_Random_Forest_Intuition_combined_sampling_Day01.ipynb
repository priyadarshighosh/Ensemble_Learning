{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest  - Bagging  Ennsemble Learning"
      ],
      "metadata": {
        "id": "buV9E0bf-37g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING THE DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "HNvHInaq_BMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eum2WGOnBeeL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the ML / Scikit learn EVERYTHING"
      ],
      "metadata": {
        "id": "egI1aKHM_G4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "import random\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier                 #Decision tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier   # bagging and Boosting\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score   # different metrices to check how our model performed"
      ],
      "metadata": {
        "id": "dy4Bw0vn4yUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Deep learning Everything"
      ],
      "metadata": {
        "id": "7EOOII0y82hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "O1qjFngb87Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing mathematical models"
      ],
      "metadata": {
        "id": "5oPnYaeAM0_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import the mathematical testing framewroks\n",
        "\n",
        "# Importing mathematical models\n",
        "import math\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "G_2PyN5pNV1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Information about the Dataset"
      ],
      "metadata": {
        "id": "XTPRT3iy9EuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X , y = make_classification( n_features=5, n_informative=5, n_redundant=0,n_clusters_per_class = 1 )"
      ],
      "metadata": {
        "id": "VD-Iz6mmHA77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(X, columns=['col1','col2','col3','col4','col5'])\n",
        "df['target'] = y\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "I_eB_oStHLJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different Types of Sampling"
      ],
      "metadata": {
        "id": "9faONk6nLFu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function of Row Sampling\n",
        "\n",
        "def sample_rows (df , percentage):\n",
        "  return df.sample(int(percentage*df.shape[0]),replace= True )"
      ],
      "metadata": {
        "id": "-IgDzVSZJB9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function of Column Sampling\n",
        "\n",
        "def sample_features(df , percentage):\n",
        "  cols = random.sample(df.columns.tolist()[:-1] ,int(percentage*df.shape[1])) # -1 as we dont count the target column\n",
        "\n",
        "  new_df = df[cols]\n",
        "  new_df['target'] = df['target']\n",
        "\n",
        "  return new_df"
      ],
      "metadata": {
        "id": "B-4eptYsKQE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function of Combined Sampling\n",
        "\n",
        "def combined_sampling(df , row_percent , col_percent):\n",
        "  new_df = sample_rows(df , row_percent)\n",
        "  new_df = sample_features(new_df , col_percent)\n",
        "  return new_df"
      ],
      "metadata": {
        "id": "o8f6aecuKQhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined Sampling"
      ],
      "metadata": {
        "id": "KSVF0yBjhzX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = combined_sampling(df , 0.5 , 0.6)\n",
        "combined_sampling(df , 0.5 , 0.6)"
      ],
      "metadata": {
        "id": "hs8EnmBIh3nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = combined_sampling(df , 0.3 , 0.8)\n",
        "combined_sampling(df , 0.3 , 0.8)"
      ],
      "metadata": {
        "id": "Cs3D-wNVi2tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = combined_sampling(df , 0.2 , 0.4)\n",
        "combined_sampling(df , 0.2 , 0.4)"
      ],
      "metadata": {
        "id": "-o6BQL1KjAq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying the Decision Tree Clasifier"
      ],
      "metadata": {
        "id": "RwbzMuh2bE4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = DecisionTreeClassifier()\n",
        "clf2 = DecisionTreeClassifier()\n",
        "clf3 = DecisionTreeClassifier()\n"
      ],
      "metadata": {
        "id": "sWfVx0XqbE4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf1.fit(df1.iloc[:,0:3] , df1.iloc[:,-1])\n",
        "clf2.fit(df2.iloc[:,0:4] , df2.iloc[:,-1])\n",
        "clf3.fit(df3.iloc[:,0:2] , df3.iloc[:,-1])"
      ],
      "metadata": {
        "id": "vclnB2hsbE4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree"
      ],
      "metadata": {
        "id": "WRJzS9bbbE4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tree(clf1)"
      ],
      "metadata": {
        "id": "65E1nx14bE4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tree(clf2)"
      ],
      "metadata": {
        "id": "KK1asBhabE4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tree(clf3)"
      ],
      "metadata": {
        "id": "Br9-cMVBbE4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w_W6PHG8iL_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We are putting the value of the first row in 3 decision tree to Manually check the prediction"
      ],
      "metadata": {
        "id": "hnz74qchc0y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf1.predict(np.array([2.391442,1.995091,-3.53688]).reshape(1,3))"
      ],
      "metadata": {
        "id": "IeTh4SXzc0y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf2.predict(np.array([-2.331446,2.391442,1.995091,-3.536883\t]).reshape(1,4))"
      ],
      "metadata": {
        "id": "BwVgbr1Nc0y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf3.predict(np.array([ -3.536883\t,1.995091\t\t\t]).reshape(1,2))"
      ],
      "metadata": {
        "id": "L9_NDsQOc0y_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
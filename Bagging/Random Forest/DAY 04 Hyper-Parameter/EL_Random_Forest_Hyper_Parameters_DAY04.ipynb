{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-Parameters of Random Forest"
      ],
      "metadata": {
        "id": "buV9E0bf-37g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING THE DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "HNvHInaq_BMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eum2WGOnBeeL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the ML / Scikit learn EVERYTHING"
      ],
      "metadata": {
        "id": "egI1aKHM_G4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import BaggingClassifier # Import BaggingClassifier from sklearn.ensemble\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.tree import DecisionTreeClassifier                 #Decision tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier   # bagging and Boosting\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score   # different metrices to check how our model performed"
      ],
      "metadata": {
        "id": "dy4Bw0vn4yUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Deep learning Everything"
      ],
      "metadata": {
        "id": "7EOOII0y82hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "O1qjFngb87Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing mathematical models"
      ],
      "metadata": {
        "id": "5oPnYaeAM0_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import the mathematical testing framewroks\n",
        "\n",
        "# Importing mathematical models\n",
        "import math\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "G_2PyN5pNV1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Loading the Dataset"
      ],
      "metadata": {
        "id": "HhdHcFjI96dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files    # we are importing the file from the device\n",
        "uploaded = files.upload()\n",
        "\n",
        "df  = pd.read_csv('heart.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pE20N_KlawbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "_QzQkiyEcpMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['target'])\n",
        "y = df['target']"
      ],
      "metadata": {
        "id": "jST9ahyPcrgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "pcPM5LD0c0_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "C5suH5ckc610"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classifier"
      ],
      "metadata": {
        "id": "RljFGw_nc_Ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "UJVDFoJ2eHlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifing with Different algorithm"
      ],
      "metadata": {
        "id": "gHPCn6CiebUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logisitic Regression"
      ],
      "metadata": {
        "id": "eb-icC6je7d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "PJyHXzpgeq3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Support Vector Classfier"
      ],
      "metadata": {
        "id": "6gLbuWXde4hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "lGfAlcBhesei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier"
      ],
      "metadata": {
        "id": "cSyt5z3Fe2ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "36AkHFxhevu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradeint Boosting Classifier"
      ],
      "metadata": {
        "id": "TLCGNlo8ez-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbc = GradientBoostingClassifier()\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = gbc.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "4YG-h2inex1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation Result"
      ],
      "metadata": {
        "id": "UIq2p3ZPfqr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score  # Cross-Validation for Random Forest\n",
        "\n",
        "np.mean(cross_val_score(rf, X, y, cv=10 , scoring='accuracy'))"
      ],
      "metadata": {
        "id": "EWDxbvXMf0JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(cross_val_score(lr, X, y, cv=10 , scoring='accuracy')) # Cross-Validation for logistic regression"
      ],
      "metadata": {
        "collapsed": true,
        "id": "11iQibPDf9L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(cross_val_score(svc, X, y, cv=10 , scoring='accuracy'))# Cross-Validation for SVC"
      ],
      "metadata": {
        "id": "iXgZRODAgR82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(cross_val_score(dt, X, y, cv=10 , scoring='accuracy'))# Cross-Validation for Decision Tree"
      ],
      "metadata": {
        "id": "ynaYU68agU85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(cross_val_score(gbc, X, y, cv=10 , scoring='accuracy'))# Cross-Validation for Gradient Booasting Classiferi"
      ],
      "metadata": {
        "id": "3x4P1FYQgVYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid SEARCH CV"
      ],
      "metadata": {
        "id": "U9iEHaDTh67U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of trees in the random forest\n",
        "n_estimators = [20,40 , 60 ,70 ]\n",
        "\n",
        "# Number of features to consider at every split\n",
        "max_features  = [0.2 , 0.3 ,  0.5 , 0.8 ]\n",
        "\n",
        "# Maximum number of levels in tree\n",
        "max_depth  = [2 , 3 , 5 ]\n",
        "\n",
        "# Maximum number of samples required\n",
        "max_samples = [0.5 ,0.65 ,  0.75]\n"
      ],
      "metadata": {
        "id": "Ep_FjDRwACUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid  = {\n",
        "              'n_estimators' : n_estimators,\n",
        "              'max_features' : max_features,\n",
        "              'max_depth' : max_depth,\n",
        "              'max_samples' : max_samples,\n",
        "}\n",
        "print (param_grid)\n"
      ],
      "metadata": {
        "id": "5ect4mLPCP81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf_grid  = GridSearchCV(estimator=rf , param_grid=param_grid , cv=5 , verbose=2 , n_jobs=-1)"
      ],
      "metadata": {
        "id": "EGl0-3vPCVog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid.fit(X_train , y_train)\n",
        "\n",
        "rf_grid.best_params_"
      ],
      "metadata": {
        "id": "fB79sUx9Bt6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid.best_score_"
      ],
      "metadata": {
        "id": "4km0Mza7DLll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Search CV"
      ],
      "metadata": {
        "id": "lpEb16v5F9I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = [20 , 40 , 60]\n",
        "\n",
        "max_features = [0.2 , 0.3 , 0.5 , 0.6 ]\n",
        "\n",
        "max_depth  = [ 2 , 4 , 6 ]\n",
        "\n",
        "max_samples = [0.5 ,0.65 ,  0.75]\n",
        "\n",
        "bootstrap = [True , False]\n",
        "\n",
        "min_samples_split = [2 , 4  ]\n",
        "\n",
        "min_samples_leaf = [ 2 , 3 , 4 ]"
      ],
      "metadata": {
        "id": "k2tORIGxGCU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "              'n_estimators' : n_estimators,\n",
        "              'max_features' : max_features,\n",
        "              'max_depth' : max_depth,\n",
        "              'max_samples' : max_samples,\n",
        "              'bootstrap' : bootstrap,\n",
        "              'min_samples_split' : min_samples_split,\n",
        "              'min_samples_leaf' : min_samples_leaf\n",
        "\n",
        "}\n",
        "print (param_grid)"
      ],
      "metadata": {
        "id": "sygazMyLHi_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "rf_grid  = RandomizedSearchCV(estimator=rf , param_distributions=param_grid , cv=5 , verbose=2 , n_jobs=-1)"
      ],
      "metadata": {
        "id": "G8IKZeOyHnlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid.fit(X_train , y_train)\n",
        "\n",
        "rf_grid.best_params_\n"
      ],
      "metadata": {
        "id": "rmCi99GOI4Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf_grid.best_score_"
      ],
      "metadata": {
        "id": "TVbl8uY-JApI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
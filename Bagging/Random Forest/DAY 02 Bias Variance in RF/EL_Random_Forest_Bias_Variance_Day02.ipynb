{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "buV9E0bf-37g"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest  - Bagging  Ennsemble Learning"
      ],
      "metadata": {
        "id": "buV9E0bf-37g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING THE DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "HNvHInaq_BMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eum2WGOnBeeL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the ML / Scikit learn EVERYTHING"
      ],
      "metadata": {
        "id": "egI1aKHM_G4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import make_circles\n",
        "import random\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier                 #Decision tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier   # bagging and Boosting\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score   # different metrices to check how our model performed"
      ],
      "metadata": {
        "id": "MZFiM3qacKbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Deep learning Everything"
      ],
      "metadata": {
        "id": "7EOOII0y82hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "O1qjFngb87Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing mathematical models"
      ],
      "metadata": {
        "id": "5oPnYaeAM0_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import the mathematical testing framewroks\n",
        "\n",
        "# Importing mathematical models\n",
        "import math\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "G_2PyN5pNV1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Information about the Dataset"
      ],
      "metadata": {
        "id": "XTPRT3iy9EuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "5t2skqujboP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X , y = make_circles(n_samples=500 , noise=0.35 , factor=0.1 , random_state=42)\n",
        "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.2 )"
      ],
      "metadata": {
        "id": "VD-Iz6mmHA77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "A0qBGfQ3b5qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[:,0] , X[:,1] , c=y)"
      ],
      "metadata": {
        "id": "fKpVFXnUcSbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for the Decision Tree"
      ],
      "metadata": {
        "id": "JV3X5eWrdolg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X_train , y_train)        # Fitting the data in the decision tree\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "x_range = np.linspace(X[:,0].min() , X[:,0].max() , 100)\n",
        "xx1 , xx2 = np.meshgrid(x_range , x_range)\n",
        "\n",
        "y_hat = dtree.predict(np.c_[xx1.ravel() , xx2.ravel()])   # prediction of the decision tre\n",
        "y_hat = y_hat.reshape(xx1.shape)\n",
        "\n",
        "plt.contourf(xx1 , xx2 , y_hat , alpha=0.3)        # We are print the prediction and the points on the Dataset\n",
        "plt.scatter(X[:,0] , X[:,1] , c=y ,cmap='viridis' , alpha=0.7)\n",
        "plt.title(\"Decision Tree Implementation of the Given Set of Points\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "m5VWwzp4drIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Implementation"
      ],
      "metadata": {
        "id": "NhPeVSNoe3q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier( n_estimators=500 , random_state=42)\n",
        "rf.fit(X_train , y_train)       # Fitting the data in the decision tree\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "x_range = np.linspace(X.min() , X.max() , 100)\n",
        "xx1 , xx2 = np.meshgrid(x_range , x_range)\n",
        "\n",
        "y_hat = rf.predict(np.c_[xx1.ravel() , xx2.ravel()])   # prediction of the decision tre\n",
        "y_hat = y_hat.reshape(xx1.shape)\n",
        "\n",
        "plt.contourf(xx1 , xx2 , y_hat , alpha=0.3)        # We are print the prediction and the points on the Dataset\n",
        "plt.scatter(X[:,0] , X[:,1] , c=y , cmap='viridis' , alpha=0.7)\n",
        "plt.title(\"Random Forest Implementation of the Given Set of Points\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "58c0xlGxfBVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression on a Self-made Dataset"
      ],
      "metadata": {
        "id": "3vK_Mi-nh4OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = 150\n",
        "n_test = 1000\n",
        "noise = 0.1\n",
        "\n",
        "# Generate data\n",
        "def f(x):\n",
        "    x = x.ravel()\n",
        "    return np.exp(-x ** 2) + 1.5 * np.exp(-(x - 2) ** 2)\n",
        "\n",
        "def generate(n_samples, noise):\n",
        "    X = np.random.rand(n_samples) * 10 - 5\n",
        "    X = np.sort(X).ravel()\n",
        "    y = np.exp(-X ** 2) + 1.5 * np.exp(-(X - 2) ** 2)\\\n",
        "        + np.random.normal(0.0, noise, n_samples)\n",
        "    X = X.reshape((n_samples, 1))\n",
        "\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = generate(n_samples=n_train, noise=noise)\n",
        "X_test, y_test = generate(n_samples=n_test, noise=noise)"
      ],
      "metadata": {
        "id": "NuxOAueugWvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,8))\n",
        "plt.scatter(X_test , f(X_test) , c=\"r\" )\n",
        "plt.scatter(X_train , y_train , c=\"b\" , s=20)\n",
        "plt.xlim(-5 , 5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wxaYT0wcggvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It as a lots of bias HBLV kind of algorithm Linear Regression"
      ],
      "metadata": {
        "id": "wDLBjf96kCCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Decision Tree on that Self-Made Dataset"
      ],
      "metadata": {
        "id": "UvxI_7r3iBwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dtree = DecisionTreeRegressor().fit(X_train, y_train)\n",
        "d_predict = dtree.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(18, 8))\n",
        "plt.plot(X_test, f(X_test), \"r\")              # plotting the decision tree line on the points\n",
        "plt.scatter(X_train, y_train, c=\"b\", s=20)\n",
        "plt.plot(X_test, d_predict, \"g\", lw=2)\n",
        "plt.xlim([-5, 5])\n",
        "plt.title(\"Decision tree, MSE = %.2f\"\n",
        "          % np.sum((y_test - d_predict) ** 2))\n",
        ""
      ],
      "metadata": {
        "id": "cDtO7wjNjKnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is trying to touch all the points even the far away noisy points it will have a high variance\n",
        ""
      ],
      "metadata": {
        "id": "bkQVtBsOjwLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest on the Self Made Dataset"
      ],
      "metadata": {
        "id": "1qmYoWS3jRYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rfr = RandomForestRegressor(n_estimators=1000).fit(X_train, y_train) # fitting and prediction of the random Forest on the points\n",
        "rf_predict = rfr.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(18, 8))    # plotting of the random Forest on the points\n",
        "plt.plot(X_test, f(X_test), \"r\")\n",
        "plt.scatter(X_train, y_train, c=\"b\", s=20)\n",
        "plt.plot(X_test, rf_predict, \"g\", lw=2)\n",
        "plt.xlim([-5, 5])\n",
        "plt.title(\"Random forest, MSE = %.2f\" % np.sum((y_test - rf_predict) ** 2));\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "ecyjUtfBjR8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is not trying very much to touch all the far away noisy points , it goes through smoothening"
      ],
      "metadata": {
        "id": "tTTcLw5Pj3p0"
      }
    }
  ]
}
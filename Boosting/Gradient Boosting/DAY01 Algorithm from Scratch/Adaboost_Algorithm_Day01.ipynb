{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "buV9E0bf-37g"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Adaboost ALgorithm from the scratch"
      ],
      "metadata": {
        "id": "buV9E0bf-37g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Libraries"
      ],
      "metadata": {
        "id": "BCgF8n91hEN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING THE DATA SCIENCE LIBRARIES"
      ],
      "metadata": {
        "id": "HNvHInaq_BMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eum2WGOnBeeL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the ML / Scikit learn EVERYTHING"
      ],
      "metadata": {
        "id": "egI1aKHM_G4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "rw9qEruauW9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier                 #Decision tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier   # bagging and Boosting\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score   # different metrices to check how our model performed"
      ],
      "metadata": {
        "id": "wRReSbVmlxcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Deep learning Everything"
      ],
      "metadata": {
        "id": "7EOOII0y82hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "O1qjFngb87Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing mathematical models"
      ],
      "metadata": {
        "id": "5oPnYaeAM0_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import the mathematical testing framewroks\n",
        "\n",
        "# Importing mathematical models\n",
        "import math\n",
        "\n",
        "from scipy import stats\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "k4tgszGRGnCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating our own Dataframe"
      ],
      "metadata": {
        "id": "uc5f7i1JhK_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "df['X1']= [1,2 ,3, 4, 5 ,6,6,7,9,9]\n",
        "df['X2']= [5,7,3,9,2,6,7,7,5,4]\n",
        "df['label']=[1,0,1,0,0,1,1,1,0,1]"
      ],
      "metadata": {
        "id": "8mtcjUW9H9og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['initial_weights'] = 1/df.shape[0]    # if there are 10 numbers then the initial weight setting will"
      ],
      "metadata": {
        "id": "6PVCRgirPJPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "KA-znTgGJvrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PLotting the Graph"
      ],
      "metadata": {
        "id": "aTPGPzVPqOZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x='X1', y='X2', data=df, hue='label')"
      ],
      "metadata": {
        "id": "J9KIAp4rKPKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We use Decision Tree , with Only 1 Max depth"
      ],
      "metadata": {
        "id": "3Oz8ppolqQ0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt1 = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "X = df.iloc[:,0:2].values\n",
        "y = df.iloc[:,2].values"
      ],
      "metadata": {
        "id": "g0ZAJWfgKsFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt1.fit(X,y)"
      ],
      "metadata": {
        "id": "qOjkYWFCLAl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "plot_tree(dt1)"
      ],
      "metadata": {
        "id": "y6hXBrk_LZs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_regions(X, y, clf=dt1, legend=2)\n",
        "        # Plotting the graph"
      ],
      "metadata": {
        "id": "670KpwfoLgwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting the Value"
      ],
      "metadata": {
        "id": "3Dq21U_RqfRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['y_pred'] = dt1.predict(X)"
      ],
      "metadata": {
        "id": "21rtcLBqMTTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "D9bcwei2NsCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating the Weight"
      ],
      "metadata": {
        "id": "6UtIfFewqnon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_model_weight(error):\n",
        "\n",
        "  return 0.5*np.log((1-error)/(error+0.000001))"
      ],
      "metadata": {
        "id": "ZSahUHXbM4rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha1 = calculate_model_weight(0.3)\n",
        "alpha1"
      ],
      "metadata": {
        "id": "kN1EFOfYNL-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing the Weight Using Alpha"
      ],
      "metadata": {
        "id": "PM_hOU1Oqr9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_row_weights(row,alpha=0.423):\n",
        "  if row['label'] == row['y_pred']:\n",
        "    return row['initial_weights']*np.exp(-alpha)\n",
        "  else:\n",
        "    return row['initial_weights']*np.exp(alpha)"
      ],
      "metadata": {
        "id": "j_YzwlCDNfZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['updated_weights'] = df.apply(update_row_weights, axis=1)"
      ],
      "metadata": {
        "id": "HxTLYP64N3aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "bq4gTR_kN8LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['updated_weights'].sum()"
      ],
      "metadata": {
        "id": "hkHu3-6ZQ6uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing the weights"
      ],
      "metadata": {
        "id": "FUDVLko6qy4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['normalized_weights'] = df['updated_weights']/df['updated_weights'].sum()"
      ],
      "metadata": {
        "id": "tv5AB0dFPtI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_BLQqyH8QJnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['normalized_weights'].sum()"
      ],
      "metadata": {
        "id": "l43UPNQ2Uj5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cumsum_upper']  = np.cumsum(df['normalized_weights'])\n",
        "df['cumsum_lower']  = df['cumsum_upper'] - df['normalized_weights']\n",
        "\n",
        "df[['X1' , 'X2' , 'label' , 'initial_weights' , 'y_pred' , 'updated_weights' , 'normalized_weights' , 'cumsum_upper' , 'cumsum_lower']]"
      ],
      "metadata": {
        "id": "dcigGXWtV8Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the New Data-Base"
      ],
      "metadata": {
        "id": "h1UDHpqzq4QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_new_database(df):\n",
        "\n",
        "  indices = []\n",
        "\n",
        "  for i in range(df.shape[0]):\n",
        "    a = np.random.random()\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "      if row['cumsum_lower'] <= a <= row['cumsum_upper']:\n",
        "        indices.append(index)\n",
        "\n",
        "\n",
        "  return indices"
      ],
      "metadata": {
        "id": "DKRtazV5XlTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_values  = create_new_database(df)\n",
        "\n",
        "index_values"
      ],
      "metadata": {
        "id": "Uz4OYb92YJCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_df = df.iloc[index_values,[0,1,2,3]]\n",
        "second_df"
      ],
      "metadata": {
        "id": "uJqPCnkcZdbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the Decision Tree again with Max depth = 1"
      ],
      "metadata": {
        "id": "32WC-euBrFcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt2 = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "X = second_df.iloc[:,0:2].values\n",
        "y = second_df.iloc[:,2].values"
      ],
      "metadata": {
        "id": "_mHO_H2pZ07U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt2.fit(X,y)"
      ],
      "metadata": {
        "id": "vwiY1EzbZ4ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tree(dt2)"
      ],
      "metadata": {
        "id": "McbsNGP-aAPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_decision_regions(X, y, clf=dt2, legend=2)"
      ],
      "metadata": {
        "id": "J-txIcUWaOJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_df['y_pred2'] = dt2.predict(X)"
      ],
      "metadata": {
        "id": "wIhQsfC5aL4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_df"
      ],
      "metadata": {
        "id": "GArw5WMCdGKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating the Alpha"
      ],
      "metadata": {
        "id": "VbXHEqn_rZGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha2 = calculate_model_weight(0.1)\n",
        "alpha2"
      ],
      "metadata": {
        "id": "ExYwxxeMchAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_row_weights(row,alpha=1.09):\n",
        "  if row['label'] == row['y_pred2']:\n",
        "    return row['initial_weights']*np.exp(-alpha)\n",
        "  else:\n",
        "    return row['initial_weights']*np.exp(alpha)"
      ],
      "metadata": {
        "id": "VAJstED2c6MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_df['updated_weights'] = second_df.apply(update_row_weights, axis=1)"
      ],
      "metadata": {
        "id": "nlK8mOIVcqU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_df"
      ],
      "metadata": {
        "id": "eQpQqyCJbgmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing the Weights"
      ],
      "metadata": {
        "id": "sYE2RP2qrRjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_df['normalized_weights'] = second_df['updated_weights']/second_df['updated_weights'].sum()"
      ],
      "metadata": {
        "id": "guNfMrK6eoNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_df"
      ],
      "metadata": {
        "id": "16xajZZnejrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_df['cumsum_upper']  = np.cumsum(second_df['normalized_weights'])\n",
        "second_df['cumsum_lower']  = second_df['cumsum_upper'] - second_df['normalized_weights']\n",
        "\n",
        "second_df"
      ],
      "metadata": {
        "id": "gvceqa5jfOoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_df['normalized_weights'].sum()"
      ],
      "metadata": {
        "id": "qAqaWVI6fTN6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
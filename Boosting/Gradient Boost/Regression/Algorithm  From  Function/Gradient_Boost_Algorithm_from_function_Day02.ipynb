{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "buV9E0bf-37g"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting ALgorithm through a Function"
      ],
      "metadata": {
        "id": "buV9E0bf-37g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Libraries"
      ],
      "metadata": {
        "id": "BCgF8n91hEN4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eum2WGOnBeeL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the ML / Scikit learn EVERYTHING"
      ],
      "metadata": {
        "id": "egI1aKHM_G4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "rw9qEruauW9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n",
        "from sklearn.compose import ColumnTransformer                       #for transforming the columns\n",
        "from sklearn.impute import SimpleImputer                             #for imputing the missing values\n",
        "from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n",
        "from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score                 # for accuracy score\n",
        "from sklearn.model_selection import cross_val_score        # for cross validation score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression           # Import the LinearRegression class\n",
        "from sklearn.metrics import mean_squared_error, r2_score    # to find out the error functions\n",
        "from sklearn.preprocessing import PolynomialFeatures , StandardScaler   # for the polunomial features\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge   # ridge Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier                 #Decision tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier   # bagging and Boosting\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score   # different metrices to check how our model performed"
      ],
      "metadata": {
        "id": "wRReSbVmlxcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Deep learning Everything"
      ],
      "metadata": {
        "id": "7EOOII0y82hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "O1qjFngb87Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing mathematical models"
      ],
      "metadata": {
        "id": "5oPnYaeAM0_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import the mathematical testing framewroks\n",
        "\n",
        "# Importing mathematical models\n",
        "import math\n",
        "\n",
        "from scipy import stats\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "k4tgszGRGnCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating our own Dataframe"
      ],
      "metadata": {
        "id": "uc5f7i1JhK_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) - 0.5\n",
        "y = 3*X[:,0]**2 +0.05*np.random.randn(100)"
      ],
      "metadata": {
        "id": "JaYpVMbdvPQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame()\n",
        "df['X']=X.squeeze()\n",
        "df['y']=y"
      ],
      "metadata": {
        "id": "Me3Sx2GyvWvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df\n"
      ],
      "metadata": {
        "id": "n1gidFIUvfIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting the graph"
      ],
      "metadata": {
        "id": "FpQlIxCWwK1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df['X'],df['y'])\n",
        "\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Scatter Plot of X vs y')\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TO4cEcV5wMx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction and Residual  ( M1  )"
      ],
      "metadata": {
        "id": "oSIiisA8xenz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Pred1'] = df['y'].mean()     #  Predicting  that is the mean of the results"
      ],
      "metadata": {
        "id": "1TlSyA74wg3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df\n"
      ],
      "metadata": {
        "id": "rzhIGAh4wqL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Res1'] = df['y'] - df['Pred1']  #  Residual  =  subtracting from Actual"
      ],
      "metadata": {
        "id": "nBnHZdYow9lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Zc7tS4MbxaKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Function of Gradient Descent"
      ],
      "metadata": {
        "id": "Rl8cC5Vs7kzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_boost(X, y, number, lr=0.1, count=1, regs=[], foo=None):\n",
        "    if number == 0:\n",
        "        return\n",
        "\n",
        "    else:\n",
        "        # do the gradient boosting\n",
        "        if count > 1:\n",
        "            y = y - regs[-1].predict(X)\n",
        "        else:\n",
        "            foo = y\n",
        "\n",
        "        tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "        tree_reg.fit(X, y)\n",
        "\n",
        "        regs.append(tree_reg)\n",
        "\n",
        "        X1 = np.linspace(-0.5, 0.5, 500)\n",
        "        # The change is made in the following line:\n",
        "        y_pred = sum(lr * regressor.predict(X1.reshape(-1, 1)) for regressor in regs)\n",
        "        # Instead of unpacking, we directly iterate through regressors and use the global lr value.\n",
        "\n",
        "        print(number)\n",
        "        plt.figure()\n",
        "        plt.plot(X1, y_pred, linewidth=2)\n",
        "        plt.plot(X[:, 0], foo, 'r.')\n",
        "        plt.show()\n",
        "\n",
        "        gradient_boost(X, y, number - 1, lr, count + 1, regs, foo=foo)"
      ],
      "metadata": {
        "id": "Ylh7KWyWAdmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is used for the plotting of the graphs"
      ],
      "metadata": {
        "id": "Zou2yDzuAmfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "X = np.random.rand(100 , 1 ) - 0.5\n",
        "y = 3*X[:,0]**2 + 0.05*np.random.randn(100)\n",
        "gradient_boost(X , y , 5,lr=1)"
      ],
      "metadata": {
        "id": "kbv9eH9AAhm7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}